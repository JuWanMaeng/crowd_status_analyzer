{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### face_data로부터 yolo를 이용해 face_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joowan/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.Conv                  [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.C2f                   [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.C2f                   [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.C2f                   [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.C2f                   [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.C2f                   [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.C2f                   [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.C2f                   [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.Conv                  [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.C2f                   [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5644480  ultralytics.nn.modules.Detect                [80, [256, 512, 512]]         \n",
      "YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=YOLO('ultralytics/models/v8/yolov8l.yaml')\n",
    "model=YOLO('weight/yolov8/l_best.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2532\n",
      "2640\n"
     ]
    }
   ],
   "source": [
    "woman_jpg_imgs=glob.glob('data/gender/0/*.jpg')\n",
    "print(len(woman_jpg_imgs))\n",
    "\n",
    "man_jpg_imgs=glob.glob('data/gender/1/*.jpg')\n",
    "print(len(man_jpg_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (333).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 107.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (243).jpg: 640x480 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2536).jpg: 640x448 2 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (649).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (271).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2095).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (412).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1639).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1170).jpg: 640x512 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1156).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (350).jpg: 448x640 1 face, 9.7ms\n",
      "Speed: 0.2ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1716).jpg: 384x640 1 face, 33.5ms\n",
      "Speed: 0.2ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1320).jpg: 640x448 1 face, 10.6ms\n",
      "Speed: 0.4ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2413).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (921).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1293).jpg: 640x576 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2238).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1364).jpg: 416x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2348).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (661).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (785).jpg: 640x448 1 face, 13.3ms\n",
      "Speed: 0.4ms preprocess, 13.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2028).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1482).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1485).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1539).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2510).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (692).jpg: 448x640 (no detections), 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1694).jpg: 480x640 1 face, 9.7ms\n",
      "Speed: 0.2ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (23).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (157).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (943).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (611).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2320).jpg: 640x576 1 face, 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (334).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (881).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2147).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2546).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2268).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1202).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (972).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (620).jpg: 640x448 1 face, 12.6ms\n",
      "Speed: 0.5ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2168).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (855).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (742).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (669).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2351).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (750).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (862).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (677).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1122).jpg: 640x288 1 face, 27.5ms\n",
      "Speed: 0.2ms preprocess, 27.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (834).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1915).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1097).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1149).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2452).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1250).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1061).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (628).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2385).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1236).jpg: 640x512 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2290).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2490).jpg: 640x640 1 face, 13.0ms\n",
      "Speed: 0.2ms preprocess, 13.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2341).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (388).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (132).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1377).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2462).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (283).jpg: 640x512 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1094).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (456).jpg: 640x384 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2482).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (594).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (932).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2279).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (965).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2366).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (494).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (700).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (373).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (655).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1828).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (288).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1431).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (924).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (356).jpg: 512x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2119).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1605).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (799).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (653).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (897).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2000).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1804).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1661).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2343).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1652).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2307).jpg: 448x640 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (989).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2458).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1503).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2158).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1430).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (134).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1042).jpg: 640x512 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1441).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1664).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1145).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2093).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2477).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (121).jpg: 576x640 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1092).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (534).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2398).jpg: 640x640 2 faces, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (577).jpg: 640x576 2 faces, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1899).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (26).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (836).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1967).jpg: 640x416 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (727).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (877).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (357).jpg: 320x640 1 face, 40.9ms\n",
      "Speed: 0.2ms preprocess, 40.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1324).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1084).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1533).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1151).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (100).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (597).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1989).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2292).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2464).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (413).jpg: 608x640 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1047).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (35).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2055).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2036).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1498).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (349).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (738).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1467).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1497).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1705).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1359).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1351).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1256).jpg: 640x416 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (917).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2335).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1541).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (730).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1334).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1562).jpg: 640x480 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (337).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (680).jpg: 640x416 2 faces, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2524).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (602).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1486).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1859).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (303).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (721).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2479).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2511).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1548).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1278).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (760).jpg: 384x640 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (782).jpg: 640x448 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (119).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2007).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (851).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (526).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (558).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1339).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2155).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (505).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2515).jpg: 640x608 2 faces, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (647).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2269).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1583).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1502).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1157).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (542).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (679).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1242).jpg: 640x416 1 face, 9.7ms\n",
      "Speed: 0.2ms preprocess, 9.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2403).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1180).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (898).jpg: 640x512 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1722).jpg: 416x640 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (786).jpg: 640x480 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1190).jpg: 480x640 (no detections), 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1378).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1383).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (143).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2006).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (335).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1143).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2425).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (238).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2494).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (507).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2534).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (473).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (865).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2184).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2137).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (346).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (125).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (281).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1708).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (474).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1900).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (792).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1132).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2025).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1833).jpg: 448x640 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (819).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (596).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1579).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1634).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (741).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2242).jpg: 640x448 1 face, 11.0ms\n",
      "Speed: 0.4ms preprocess, 11.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1513).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (326).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2543).jpg: 640x576 1 face, 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (624).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1894).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1392).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2128).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1454).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1830).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1495).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1873).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2098).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2363).jpg: 640x448 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (189).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1113).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (216).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (433).jpg: 640x352 1 face, 8.5ms\n",
      "Speed: 0.1ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2271).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (406).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2276).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2301).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (664).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (392).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (584).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (445).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (375).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1730).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (229).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1616).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (501).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2353).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1395).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2391).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2324).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1703).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1266).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2256).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2084).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (393).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2471).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (269).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (546).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1371).jpg: 640x480 4 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2005).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (389).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2299).jpg: 640x512 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1380).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (670).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1058).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (610).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (656).jpg: 640x512 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (595).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1958).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2344).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (158).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1822).jpg: 640x448 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1946).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (130).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1658).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (994).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1754).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1741).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (206).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1138).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1343).jpg: 640x416 2 faces, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1521).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (565).jpg: 640x448 2 faces, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (396).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1451).jpg: 640x448 2 faces, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1677).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1141).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (842).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1538).jpg: 640x448 1 face, 10.0ms\n",
      "Speed: 0.3ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1300).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1101).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2131).jpg: 448x640 1 face, 9.9ms\n",
      "Speed: 0.2ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1814).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (643).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2542).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1520).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1975).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1434).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1632).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (822).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1006).jpg: 640x544 (no detections), 12.8ms\n",
      "Speed: 0.3ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1663).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2520).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1572).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (102).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1366).jpg: 544x640 1 face, 13.2ms\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1271).jpg: 640x448 1 face, 9.6ms\n",
      "Speed: 0.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1464).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2423).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1161).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (765).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (618).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1805).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1304).jpg: 384x640 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (912).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1205).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (440).jpg: 448x640 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (471).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2506).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1305).jpg: 640x352 1 face, 8.3ms\n",
      "Speed: 0.1ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1673).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1191).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1142).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1211).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (16).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1449).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (203).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1303).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1316).jpg: 640x480 2 faces, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1836).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1597).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (308).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1465).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2484).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1490).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (338).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1181).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1825).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2374).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2469).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1136).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2519).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2175).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2138).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2509).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1688).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1064).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1435).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (153).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (667).jpg: 416x640 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (608).jpg: 384x640 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (837).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1527).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (138).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1775).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (286).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2181).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1080).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1252).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2483).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (270).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2486).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (199).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (248).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1000).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (222).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1297).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (401).jpg: 640x544 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1369).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1582).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1318).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1889).jpg: 416x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (180).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (105).jpg: 384x640 3 faces, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1933).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (95).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (767).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (864).jpg: 480x640 1 face, 10.4ms\n",
      "Speed: 0.2ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2427).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (757).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (173).jpg: 384x640 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1072).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (854).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (251).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (39).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1389).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (73).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2148).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1766).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (525).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1079).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1948).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1276).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (737).jpg: 640x448 (no detections), 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2454).jpg: 448x640 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (899).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1443).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (341).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (233).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2180).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1516).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1144).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2039).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (160).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2246).jpg: 640x576 1 face, 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (36).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1476).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2404).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (521).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1625).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1110).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (294).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2488).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (475).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (882).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (872).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (992).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2434).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1500).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1590).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1530).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (583).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (685).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2370).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1238).jpg: 416x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1406).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (352).jpg: 384x640 (no detections), 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (517).jpg: 416x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1788).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (490).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (636).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (360).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1691).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (947).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2325).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1376).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1765).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (570).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1553).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (940).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2143).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2270).jpg: 384x640 1 face, 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (707).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (354).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (351).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1526).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2132).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1228).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (646).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1150).jpg: 320x640 (no detections), 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (923).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (593).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2057).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1044).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1984).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (285).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (915).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1886).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1792).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (84).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (891).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (945).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2498).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (6).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1947).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (885).jpg: 640x384 1 face, 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (589).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (268).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1931).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1188).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2386).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1440).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (272).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1198).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1063).jpg: 640x640 (no detections), 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (215).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1916).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (210).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (240).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2547).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1469).jpg: 640x512 1 face, 10.2ms\n",
      "Speed: 0.5ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1786).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (658).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1698).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2449).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1951).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2375).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (712).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (808).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (762).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1227).jpg: 512x640 1 face, 15.7ms\n",
      "Speed: 0.5ms preprocess, 15.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (807).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2173).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1511).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2182).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2153).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.3ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2364).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (946).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2518).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (483).jpg: 320x640 (no detections), 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2066).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1162).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2226).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1323).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (988).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (482).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (616).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (893).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (970).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1898).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (831).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2116).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2188).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (20).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1386).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (681).jpg: 640x544 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (522).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (223).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1456).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2273).jpg: 608x640 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1333).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (830).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1217).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (531).jpg: 640x480 1 face, 10.4ms\n",
      "Speed: 0.4ms preprocess, 10.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1251).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.3ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1556).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1769).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (103).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (65).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1713).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2467).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2424).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2241).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2384).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (996).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (3).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (359).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1273).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2530).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2533).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1422).jpg: 640x448 1 face, 9.6ms\n",
      "Speed: 0.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (195).jpg: 640x384 1 face, 8.5ms\n",
      "Speed: 0.1ms preprocess, 8.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2056).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (366).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (10).jpg: 640x544 1 face, 12.9ms\n",
      "Speed: 0.4ms preprocess, 12.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2001).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (205).jpg: 640x544 2 faces, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1760).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1821).jpg: 640x640 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1399).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1835).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1436).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1275).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1049).jpg: 640x576 (no detections), 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1745).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1163).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1608).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (149).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2244).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (151).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (266).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2336).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1508).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (42).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2308).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1952).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2302).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2419).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (491).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1494).jpg: 640x608 2 faces, 13.9ms\n",
      "Speed: 0.3ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1547).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (892).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1624).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (191).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1213).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1580).jpg: 640x544 1 face, 12.5ms\n",
      "Speed: 0.2ms preprocess, 12.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1566).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2183).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (813).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (127).jpg: 448x640 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (942).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1515).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2162).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1565).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.1ms preprocess, 13.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2411).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1992).jpg: 448x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (58).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1120).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1532).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (156).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1292).jpg: 640x320 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (60).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (437).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1096).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2409).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1040).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1018).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (97).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (171).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1840).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1907).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1179).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2159).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1442).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1444).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (369).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (900).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1700).jpg: 480x640 (no detections), 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (44).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1737).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (117).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (214).jpg: 640x384 1 face, 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (45).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (904).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (184).jpg: 320x640 1 face, 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1470).jpg: 640x512 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (745).jpg: 640x512 2 faces, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2136).jpg: 576x640 1 face, 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (306).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (449).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1912).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (381).jpg: 640x480 2 faces, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1337).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1736).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2068).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2263).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1603).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (780).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1839).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (609).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2077).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (480).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1906).jpg: 640x384 1 face, 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (159).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2347).jpg: 640x480 2 faces, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (423).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (794).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1225).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1806).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (928).jpg: 448x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (759).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2200).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (462).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1657).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1996).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1610).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1267).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (113).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2009).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1960).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1477).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1345).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1126).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (246).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (922).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (225).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (860).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (784).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (944).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (46).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (687).jpg: 640x544 2 faces, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1966).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (950).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1076).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2152).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (115).jpg: 384x640 (no detections), 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1137).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (377).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2323).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1726).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (317).jpg: 384x640 1 face, 8.9ms\n",
      "Speed: 0.3ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (417).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1832).jpg: 640x576 1 face, 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (330).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1959).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1968).jpg: 640x320 1 face, 8.2ms\n",
      "Speed: 0.2ms preprocess, 8.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (318).jpg: 640x480 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1890).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (85).jpg: 544x640 1 face, 13.2ms\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (383).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1248).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (516).jpg: 640x608 2 faces, 14.0ms\n",
      "Speed: 0.3ms preprocess, 14.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1312).jpg: 640x448 1 face, 9.7ms\n",
      "Speed: 0.3ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1797).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (374).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2032).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1715).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (403).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1461).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1317).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (129).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2359).jpg: 640x544 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (843).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2015).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (459).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2121).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (528).jpg: 640x448 1 face, 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1564).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2369).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1747).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (778).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1803).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1666).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (348).jpg: 640x544 (no detections), 12.9ms\n",
      "Speed: 0.4ms preprocess, 12.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2503).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1073).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1083).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1171).jpg: 384x640 (no detections), 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1963).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (639).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1284).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2453).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1509).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (340).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (282).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2548).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1314).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (582).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (906).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1427).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1381).jpg: 640x640 2 faces, 13.2ms\n",
      "Speed: 0.4ms preprocess, 13.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1070).jpg: 640x512 1 face, 9.6ms\n",
      "Speed: 0.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1911).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (612).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2064).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1555).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1518).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1355).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (434).jpg: 640x640 2 faces, 12.8ms\n",
      "Speed: 0.1ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2089).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1943).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (678).jpg: 416x640 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1038).jpg: 640x480 1 face, 10.0ms\n",
      "Speed: 0.4ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1563).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1265).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2448).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1820).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1090).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1750).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2455).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1212).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1995).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (683).jpg: 640x640 (no detections), 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2166).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1581).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2444).jpg: 416x640 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (137).jpg: 640x544 (no detections), 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (880).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (237).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2539).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1543).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (166).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2041).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (390).jpg: 640x512 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1274).jpg: 640x480 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (713).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1051).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1917).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1857).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (841).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (279).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (591).jpg: 640x480 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (280).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (202).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2112).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (637).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1154).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1816).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1457).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (927).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (322).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (496).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (666).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (547).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (25).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (420).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (234).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1589).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (699).jpg: 640x544 2 faces, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (731).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (694).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1626).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2065).jpg: 640x544 2 faces, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (817).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1387).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (561).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1729).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1780).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (873).jpg: 640x384 1 face, 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (250).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (986).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (651).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2252).jpg: 640x480 3 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2493).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (204).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1591).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1215).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2017).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1576).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1668).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2321).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (487).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1025).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (336).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1512).jpg: 608x640 1 face, 14.0ms\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1953).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (524).jpg: 544x640 1 face, 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (632).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2111).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (510).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1855).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2218).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (291).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2487).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1270).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (845).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (821).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (502).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1687).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1075).jpg: 480x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1861).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2365).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (265).jpg: 480x640 1 face, 13.5ms\n",
      "Speed: 0.5ms preprocess, 13.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2415).jpg: 544x640 1 face, 13.3ms\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1789).jpg: 640x640 1 face, 13.2ms\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1481).jpg: 416x640 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2157).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2328).jpg: 576x640 1 face, 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (966).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (426).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1504).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1262).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (987).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.3ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1283).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (19).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (863).jpg: 640x448 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2161).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (523).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1429).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (135).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.1ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1261).jpg: 640x544 (no detections), 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (385).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2038).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (163).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (310).jpg: 640x576 (no detections), 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2222).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1100).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1458).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1519).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2397).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2288).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (209).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1686).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1777).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (177).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2350).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2160).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (697).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2264).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (395).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2092).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (728).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1594).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (83).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1785).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1749).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (242).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1560).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2527).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1985).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1417).jpg: 608x640 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2394).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (979).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2489).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1701).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1130).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2266).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1542).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.3ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2295).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (823).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1127).jpg: 544x640 1 face, 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (62).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1893).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (186).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1103).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (485).jpg: 640x320 1 face, 7.9ms\n",
      "Speed: 0.1ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (9).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2151).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2293).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1679).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2505).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1650).jpg: 640x320 1 face, 7.9ms\n",
      "Speed: 0.2ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1030).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1014).jpg: 640x512 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1891).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2283).jpg: 640x544 1 face, 12.8ms\n",
      "Speed: 0.1ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1249).jpg: 384x640 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (72).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1622).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (563).jpg: 448x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2340).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (98).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (68).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2156).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2096).jpg: 640x512 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1592).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (512).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2228).jpg: 640x512 2 faces, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1259).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (211).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (438).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (451).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2113).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (739).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2529).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (181).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1791).jpg: 512x640 1 face, 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (241).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2189).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1902).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (720).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (435).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (365).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2478).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (930).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (162).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1045).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1882).jpg: 640x512 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (716).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1241).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1910).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1487).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (194).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2150).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2177).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (709).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1408).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (429).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2262).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (458).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2209).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (328).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2440).jpg: 608x640 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (919).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1098).jpg: 448x640 1 face, 11.8ms\n",
      "Speed: 0.4ms preprocess, 11.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (245).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1116).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1846).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (953).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (495).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1492).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2020).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1052).jpg: 640x480 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (299).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1719).jpg: 480x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (427).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (958).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (478).jpg: 448x640 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1540).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (729).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (723).jpg: 544x640 1 face, 13.2ms\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1131).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2215).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2079).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (503).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1615).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1926).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2013).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1164).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1740).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2198).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (974).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1848).jpg: 384x640 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1977).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (391).jpg: 640x480 (no detections), 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1704).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1683).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1010).jpg: 640x544 2 faces, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1134).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (198).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (931).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (224).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (735).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1570).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.1ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1758).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.3ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1017).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1714).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (775).jpg: 640x512 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1059).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (776).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2470).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1936).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2372).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (489).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2491).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1169).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (763).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2431).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (801).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (236).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (553).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2163).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2421).jpg: 640x640 1 face, 13.0ms\n",
      "Speed: 0.2ms preprocess, 13.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1790).jpg: 640x576 1 face, 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (954).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1360).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1117).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2247).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2508).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (793).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1208).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1488).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2459).jpg: 640x480 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1841).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (61).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (832).jpg: 640x384 1 face, 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (606).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1325).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (520).jpg: 640x512 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2004).jpg: 640x512 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2012).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (70).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2497).jpg: 640x320 1 face, 7.9ms\n",
      "Speed: 0.1ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (663).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2281).jpg: 640x544 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (230).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (688).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (641).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2280).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1055).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (169).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1357).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1628).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (343).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1400).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2016).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1697).jpg: 640x544 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (896).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1234).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (311).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1362).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1223).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2492).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1531).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (604).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (384).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2221).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2528).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1779).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1174).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (850).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (758).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1690).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (188).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (975).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (24).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1796).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2080).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (43).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1409).jpg: 448x640 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1172).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.3ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1600).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (75).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2021).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1971).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (982).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (519).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (86).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (332).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2010).jpg: 640x640 1 face, 12.5ms\n",
      "Speed: 0.1ms preprocess, 12.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (533).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (262).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1738).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (879).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1751).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2362).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1980).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2097).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2354).jpg: 640x448 1 face, 10.1ms\n",
      "Speed: 0.4ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1753).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2337).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1321).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (227).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2282).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (809).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2086).jpg: 640x448 2 faces, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1453).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (937).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2109).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (874).jpg: 320x640 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (645).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (704).jpg: 640x448 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1844).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1197).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (172).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1883).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1523).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2327).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (467).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1027).jpg: 640x320 1 face, 7.9ms\n",
      "Speed: 0.2ms preprocess, 7.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1104).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (859).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1768).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1028).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1784).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1895).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (22).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (124).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1778).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (770).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (789).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1414).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1054).jpg: 384x640 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2102).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1609).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (175).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (957).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1770).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (711).jpg: 640x576 (no detections), 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2046).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.3ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1111).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1827).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (479).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1220).jpg: 640x512 2 faces, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1772).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (477).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1978).jpg: 640x480 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1432).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1175).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2030).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (753).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2049).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1002).jpg: 640x480 2 faces, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1588).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1468).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1168).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2076).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (926).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1166).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1818).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2251).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2210).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1499).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (959).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (90).jpg: 640x448 1 face, 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (112).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2407).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2549).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1544).jpg: 640x576 (no detections), 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1812).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (182).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (493).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (815).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (949).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2378).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (552).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2393).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2186).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1850).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (532).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1834).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (771).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (674).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1794).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (568).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (196).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2517).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1056).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1847).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1479).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2420).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2134).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (136).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (253).jpg: 448x640 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1102).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (408).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (114).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1672).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2277).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1326).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (148).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2144).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1373).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1611).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1372).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2194).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (691).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1480).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (446).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (450).jpg: 448x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1187).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2522).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (170).jpg: 544x640 1 face, 14.3ms\n",
      "Speed: 0.3ms preprocess, 14.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2062).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1471).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (301).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1167).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1257).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (481).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1003).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1306).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1927).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (682).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1313).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (708).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2253).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2233).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1554).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (889).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (312).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (857).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2214).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (733).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (353).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2257).jpg: 448x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (110).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1613).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1941).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1192).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1787).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2429).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1587).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2507).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1507).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (370).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (962).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2190).jpg: 640x544 2 faces, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2368).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1913).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (732).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.3ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2196).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (894).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (13).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2031).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2322).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (165).jpg: 576x640 1 face, 13.8ms\n",
      "Speed: 0.4ms preprocess, 13.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2457).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1674).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1620).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (849).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1450).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1375).jpg: 480x640 (no detections), 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (627).jpg: 480x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (231).jpg: 384x640 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1031).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1247).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2443).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (907).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1642).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2054).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (221).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2396).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (244).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (579).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1290).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (840).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (17).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (983).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (193).jpg: 640x576 (no detections), 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (652).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1200).jpg: 640x640 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (307).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.1ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1245).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1374).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1478).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1706).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1725).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2223).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1085).jpg: 640x576 (no detections), 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1829).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (228).jpg: 640x544 1 face, 12.4ms\n",
      "Speed: 0.1ms preprocess, 12.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1964).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (518).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1866).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (492).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2390).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1568).jpg: 576x640 1 face, 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1246).jpg: 640x576 2 faces, 13.6ms\n",
      "Speed: 0.1ms preprocess, 13.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (436).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1631).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (509).jpg: 384x640 1 face, 10.2ms\n",
      "Speed: 0.4ms preprocess, 10.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1938).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1813).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (878).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1296).jpg: 544x640 1 face, 13.2ms\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2029).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (320).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (968).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1421).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2248).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1988).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (12).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (263).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2124).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1781).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1091).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2212).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (548).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (746).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2289).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1924).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2339).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (325).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1524).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1332).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2260).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2169).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1932).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (257).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2217).jpg: 640x480 1 face, 9.8ms\n",
      "Speed: 0.3ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1795).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1807).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (314).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (796).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (226).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (555).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (557).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (274).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (66).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (472).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (302).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2104).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (67).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (18).jpg: 640x416 2 faces, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1119).jpg: 640x416 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (47).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1286).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (993).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1596).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1761).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1831).jpg: 576x640 1 face, 13.6ms\n",
      "Speed: 0.1ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (820).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1801).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1962).jpg: 640x448 1 face, 9.7ms\n",
      "Speed: 0.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1447).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2088).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1350).jpg: 640x480 2 faces, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (795).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2501).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (339).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2329).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2091).jpg: 640x448 1 face, 9.9ms\n",
      "Speed: 0.1ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (601).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2063).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1689).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1983).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2106).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (541).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1335).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (431).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (665).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1254).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1060).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (452).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (41).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (432).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1088).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1239).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2070).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1944).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1404).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1558).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1551).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1466).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1623).jpg: 640x448 1 face, 11.9ms\n",
      "Speed: 0.5ms preprocess, 11.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (936).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1455).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1319).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2433).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2048).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (736).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1289).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1945).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2274).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (76).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2047).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1331).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2383).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (428).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1033).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2345).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2219).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1353).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1584).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1887).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (5).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1133).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1081).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1743).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1843).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (626).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2026).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1183).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.1ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (398).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (935).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (323).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (556).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (995).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (657).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1462).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (109).jpg: 480x640 (no detections), 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (106).jpg: 640x512 1 face, 9.2ms\n",
      "Speed: 0.4ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (791).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (605).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2463).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (190).jpg: 640x640 1 face, 13.0ms\n",
      "Speed: 0.3ms preprocess, 13.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2532).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (866).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1854).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1342).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2125).jpg: 640x608 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (990).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2240).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1990).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1483).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2371).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1361).jpg: 448x640 1 face, 9.6ms\n",
      "Speed: 0.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1062).jpg: 640x576 1 face, 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (615).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2512).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1029).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1720).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1923).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (783).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1837).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1662).jpg: 640x352 1 face, 8.3ms\n",
      "Speed: 0.1ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2373).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1557).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (499).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1685).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (88).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2110).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1506).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (379).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2287).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2526).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (614).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (569).jpg: 640x640 2 faces, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (592).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (79).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1746).jpg: 640x576 1 face, 13.5ms\n",
      "Speed: 0.2ms preprocess, 13.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (37).jpg: 640x512 (no detections), 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2024).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (380).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (376).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (220).jpg: 384x640 1 face, 8.5ms\n",
      "Speed: 0.1ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1173).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2531).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2298).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (400).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1656).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1036).jpg: 544x640 1 face, 13.3ms\n",
      "Speed: 0.4ms preprocess, 13.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1892).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2078).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (469).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (810).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2317).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2485).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1268).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (977).jpg: 480x640 (no detections), 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1011).jpg: 384x640 (no detections), 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (167).jpg: 640x448 1 face, 11.6ms\n",
      "Speed: 0.6ms preprocess, 11.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2468).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (82).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2114).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (29).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2376).jpg: 640x480 2 faces, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1253).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (54).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (442).jpg: 608x640 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1232).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1472).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2537).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (200).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.1ms preprocess, 13.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2426).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2011).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (848).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (631).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1860).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (690).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2107).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (766).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2439).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1919).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1878).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1071).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2105).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2541).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1549).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (856).jpg: 576x640 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (447).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (247).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2258).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1125).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1424).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2408).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1767).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1233).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (219).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (951).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (835).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (78).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1680).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1474).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1021).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (755).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1954).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (744).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1410).jpg: 640x352 1 face, 8.9ms\n",
      "Speed: 0.3ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (867).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (123).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1020).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (404).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1368).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (120).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.3ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2130).jpg: 640x544 2 faces, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1214).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2313).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1808).jpg: 544x640 1 face, 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (634).jpg: 640x576 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1069).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1981).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (256).jpg: 640x512 2 faces, 9.0ms\n",
      "Speed: 0.3ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1731).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (554).jpg: 640x480 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (581).jpg: 640x544 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (443).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (466).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (676).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (870).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (290).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2178).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2435).jpg: 576x640 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1155).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2461).jpg: 384x640 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2432).jpg: 480x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1771).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2120).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2145).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1099).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.3ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (463).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1491).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (258).jpg: 640x480 2 faces, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (185).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1204).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1864).jpg: 640x640 2 faces, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1884).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (444).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1811).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (726).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (876).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (562).jpg: 448x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1226).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1363).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1604).jpg: 640x544 1 face, 12.8ms\n",
      "Speed: 0.3ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (7).jpg: 640x544 2 faces, 12.4ms\n",
      "Speed: 0.2ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2083).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (296).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2050).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2382).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1309).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2259).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (751).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1340).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1129).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1121).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1009).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (118).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (515).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1066).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1599).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (981).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (276).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1272).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2338).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (122).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1799).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1994).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1281).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (826).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (218).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (141).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (938).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1868).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.2ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2204).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (749).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1974).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1707).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1382).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1089).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2286).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (254).jpg: 608x640 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1152).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1577).jpg: 640x480 1 face, 13.0ms\n",
      "Speed: 0.5ms preprocess, 13.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1567).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1852).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2052).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (629).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2171).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (722).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2437).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2311).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (80).jpg: 384x640 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (956).jpg: 384x640 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (192).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (933).jpg: 640x448 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1484).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2193).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1757).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1322).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1728).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2239).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (619).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1619).jpg: 448x640 1 face, 9.8ms\n",
      "Speed: 0.3ms preprocess, 9.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (887).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1885).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (140).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2203).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2261).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (382).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2410).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2392).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (824).jpg: 640x480 2 faces, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2309).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (734).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1961).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2213).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2115).jpg: 544x640 1 face, 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (654).jpg: 640x480 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1423).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (875).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (52).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1209).jpg: 640x512 (no detections), 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (671).jpg: 384x640 1 face, 12.7ms\n",
      "Speed: 0.5ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1139).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2357).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (252).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1057).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1282).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (207).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1782).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2412).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (239).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2504).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1032).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (273).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.3ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (133).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (911).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1390).jpg: 608x640 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1086).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2296).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1288).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1819).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2100).jpg: 640x544 1 face, 12.4ms\n",
      "Speed: 0.2ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (630).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2473).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1475).jpg: 640x448 1 face, 10.3ms\n",
      "Speed: 0.4ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2069).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1413).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2249).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1230).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1146).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1647).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (96).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (952).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (441).jpg: 640x544 (no detections), 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (405).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1909).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (984).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (316).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (718).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2172).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (486).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2538).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2521).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1344).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1176).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (74).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (985).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (673).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (38).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (696).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (717).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2072).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1203).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1991).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2428).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (747).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1755).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1199).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2027).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1403).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (142).jpg: 640x576 (no detections), 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (497).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1742).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (321).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2430).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2018).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (913).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2058).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1956).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1005).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2495).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1872).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1879).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1641).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1874).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (702).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1004).jpg: 640x544 2 faces, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (128).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (777).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (703).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1201).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1394).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (929).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2418).jpg: 640x480 3 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (884).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2207).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (901).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2304).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1897).jpg: 640x544 2 faces, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2291).jpg: 640x512 (no detections), 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2500).jpg: 640x480 1 face, 9.7ms\n",
      "Speed: 0.2ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1023).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1575).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1774).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1426).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2014).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2422).jpg: 608x640 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1918).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (886).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1505).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2122).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1148).jpg: 640x448 1 face, 10.7ms\n",
      "Speed: 0.3ms preprocess, 10.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2285).jpg: 480x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (448).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (833).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1724).jpg: 640x480 2 faces, 9.2ms\n",
      "Speed: 0.3ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2108).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1078).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1473).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1957).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1065).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1695).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2399).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (139).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (603).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2042).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1744).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1068).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (30).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (761).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2550).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2516).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (998).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (725).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1627).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (183).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (902).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1416).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (4).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1114).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1669).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (934).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2040).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2451).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2075).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (948).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (530).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2043).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (705).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (853).jpg: 640x512 (no detections), 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2082).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1535).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2330).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1412).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1048).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (287).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1635).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2060).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (407).jpg: 640x512 1 face, 9.2ms\n",
      "Speed: 0.4ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (978).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (150).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1347).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1905).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2297).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1356).jpg: 640x448 (no detections), 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (684).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1920).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (49).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (107).jpg: 448x640 1 face, 9.6ms\n",
      "Speed: 0.3ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (77).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1773).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (298).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1692).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (545).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1870).jpg: 640x448 1 face, 12.9ms\n",
      "Speed: 0.5ms preprocess, 12.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1721).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1764).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (973).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.2ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (549).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1925).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2319).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (367).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1877).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (623).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (402).jpg: 640x480 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1418).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2284).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2334).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (914).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1734).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1618).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1869).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (455).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (806).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1684).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (686).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2250).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1231).jpg: 608x640 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2417).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1876).jpg: 608x640 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (53).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2085).jpg: 640x480 1 face, 10.0ms\n",
      "Speed: 0.2ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2306).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1585).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1601).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (174).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2446).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (397).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1655).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1087).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1463).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2305).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1195).jpg: 640x576 (no detections), 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (293).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1536).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (539).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (212).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (650).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1185).jpg: 640x544 (no detections), 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1210).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.3ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (868).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2211).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1949).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (111).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2045).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (825).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (939).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1235).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (152).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (8).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (574).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (94).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2243).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2481).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1128).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (910).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2475).jpg: 640x576 (no detections), 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (514).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1160).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1393).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1147).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1922).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1221).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (304).jpg: 640x512 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2300).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2127).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (638).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1348).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (261).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1095).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2191).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1285).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1308).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1574).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2377).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1928).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1219).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1537).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2436).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1970).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1665).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (126).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1224).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (961).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1862).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (756).jpg: 480x640 (no detections), 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2405).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1940).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (131).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2067).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1934).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1676).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1053).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2195).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (812).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1723).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2450).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1039).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2118).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (971).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1336).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1112).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1595).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (31).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1035).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2525).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1338).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2474).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1277).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1810).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.3ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2349).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1653).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2465).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (852).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1748).jpg: 544x640 1 face, 13.2ms\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2315).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2216).jpg: 640x480 2 faces, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1979).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (535).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2123).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2022).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1118).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (773).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (706).jpg: 640x544 (no detections), 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (551).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2360).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (560).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (506).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (55).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (818).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (275).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1514).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2535).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2401).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (903).jpg: 640x480 (no detections), 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1667).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1135).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2361).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1969).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1875).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1571).jpg: 640x480 3 faces, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1437).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1578).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (93).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1206).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1735).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (277).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1856).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (607).jpg: 640x576 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (599).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2380).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (300).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2499).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1671).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2389).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (827).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2197).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (461).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (387).jpg: 480x640 (no detections), 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1279).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2254).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (787).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2101).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (34).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1529).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (255).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2502).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (564).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2135).jpg: 608x640 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2208).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2416).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1082).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2332).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2179).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (453).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1263).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1026).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1229).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1043).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (48).jpg: 640x320 1 face, 7.9ms\n",
      "Speed: 0.1ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1019).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1678).jpg: 640x512 1 face, 10.6ms\n",
      "Speed: 0.4ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1329).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1093).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2456).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2466).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1264).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (598).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1675).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2139).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (104).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (421).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2087).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (828).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1298).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2406).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2545).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1682).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1802).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1903).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1222).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1358).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2034).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1301).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (847).jpg: 640x576 2 faces, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1614).jpg: 640x448 1 face, 9.6ms\n",
      "Speed: 0.4ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1712).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2441).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (642).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (235).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2356).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (59).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (621).jpg: 640x480 3 faces, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1550).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1617).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (800).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1050).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1016).jpg: 320x640 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1561).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1367).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (724).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (668).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (790).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.3ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (57).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (179).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (213).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2331).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (410).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (260).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1159).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (99).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1012).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1379).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2199).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1586).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (644).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (805).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1904).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1438).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2272).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1646).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1370).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (15).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (309).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1105).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1311).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1973).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1815).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2185).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1793).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1460).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (278).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1851).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (313).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2447).jpg: 640x544 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1999).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2414).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (51).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1888).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2310).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2523).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (411).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1660).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (788).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2265).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1659).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2019).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (342).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1178).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (588).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1845).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2202).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.3ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (916).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1037).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2303).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (319).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1842).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2294).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1310).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1606).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1207).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1315).jpg: 480x640 1 face, 9.7ms\n",
      "Speed: 0.2ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2442).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1123).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (969).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1756).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2333).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1826).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (764).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (178).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (960).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (672).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (675).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2033).jpg: 480x640 (no detections), 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1935).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1196).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (567).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (698).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (386).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2318).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (424).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (28).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.2ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (81).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1074).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (457).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1077).jpg: 640x448 (no detections), 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (422).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1158).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1177).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1067).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (625).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (895).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (689).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1752).jpg: 640x544 1 face, 12.4ms\n",
      "Speed: 0.2ms preprocess, 12.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (963).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (550).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (87).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (208).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (305).jpg: 480x640 (no detections), 9.7ms\n",
      "Speed: 0.2ms preprocess, 9.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (590).jpg: 640x544 (no detections), 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1800).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (101).jpg: 640x640 (no detections), 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1987).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1244).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (617).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1452).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1552).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1858).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1385).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2154).jpg: 640x576 2 faces, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (781).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (871).jpg: 640x640 2 faces, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1921).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1115).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (168).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2314).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (527).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (580).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (315).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (378).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (575).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2230).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1354).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2081).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.3ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1607).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1612).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2540).jpg: 640x544 2 faces, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1871).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2438).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (460).jpg: 640x352 1 face, 8.3ms\n",
      "Speed: 0.2ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (201).jpg: 640x512 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1638).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (693).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1718).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1696).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1106).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (816).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1109).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1007).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2002).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1445).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (362).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (331).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1732).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (844).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1711).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (752).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2051).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (399).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2544).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (511).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (804).jpg: 640x512 (no detections), 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (146).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (504).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2235).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2174).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (695).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2176).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2255).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1908).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1993).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2346).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1525).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (566).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2206).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1496).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1024).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1593).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (955).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2225).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1287).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2496).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (538).jpg: 640x512 (no detections), 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2142).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2073).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (464).jpg: 640x544 (no detections), 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2141).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2140).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (161).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (289).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1330).jpg: 576x640 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (883).jpg: 640x576 2 faces, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1034).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2094).jpg: 640x640 2 faces, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (144).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2472).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1327).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (719).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1817).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2245).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1633).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1008).jpg: 640x512 1 face, 9.7ms\n",
      "Speed: 0.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (633).jpg: 640x512 (no detections), 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1302).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2201).jpg: 640x608 2 faces, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (662).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (861).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (803).jpg: 448x640 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (415).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (991).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (839).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1709).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1448).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2514).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (500).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2460).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1865).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1428).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1419).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1398).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2146).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1965).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (748).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2129).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1501).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (740).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1280).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (476).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1237).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (63).jpg: 448x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (11).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1602).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (544).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (540).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1411).jpg: 640x544 2 faces, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1384).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (585).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1407).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2275).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1015).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2379).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (498).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (470).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (232).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1654).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (147).jpg: 544x640 1 face, 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1929).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (997).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (797).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (297).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2192).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1937).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2071).jpg: 640x448 1 face, 12.8ms\n",
      "Speed: 0.4ms preprocess, 12.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2133).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1717).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (488).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1489).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2278).jpg: 416x640 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2342).jpg: 640x544 2 faces, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2237).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1194).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2395).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (14).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (292).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1446).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1295).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1645).jpg: 640x512 2 faces, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1243).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (33).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1759).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (484).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1258).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (967).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2149).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1401).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2355).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1165).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (802).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (155).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (622).jpg: 576x640 1 face, 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2035).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (905).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (613).jpg: 640x288 1 face, 8.0ms\n",
      "Speed: 0.2ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (869).jpg: 512x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (858).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (890).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1415).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1853).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2445).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1307).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1397).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (586).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (418).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1648).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (361).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (743).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2267).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (439).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (425).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1670).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2236).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1522).jpg: 640x544 2 faces, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1108).jpg: 576x640 (no detections), 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2388).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (715).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2170).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1041).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1783).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1255).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (846).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (368).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (573).jpg: 640x416 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (116).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (798).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2008).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (27).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1838).jpg: 384x640 1 face, 9.0ms\n",
      "Speed: 0.3ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (768).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (941).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (264).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (217).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (543).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1896).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (344).jpg: 640x512 (no detections), 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (355).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1216).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1763).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (465).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1189).jpg: 576x640 1 face, 13.6ms\n",
      "Speed: 0.3ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1493).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (409).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (572).jpg: 640x576 2 faces, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2513).jpg: 640x448 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (21).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (537).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1240).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1459).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (145).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1001).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2165).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1727).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (576).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (176).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (364).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (838).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1798).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (468).jpg: 416x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1569).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (89).jpg: 640x512 1 face, 10.7ms\n",
      "Speed: 0.5ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1439).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1939).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (513).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (187).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2316).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1046).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2381).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1184).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1218).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (327).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (259).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2126).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1294).jpg: 640x640 (no detections), 13.0ms\n",
      "Speed: 0.4ms preprocess, 13.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1849).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (920).jpg: 640x480 3 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (587).jpg: 640x416 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1396).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2090).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1901).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1733).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1341).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2227).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1867).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1863).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (774).jpg: 608x640 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1193).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1153).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1640).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2551).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1022).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2167).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1365).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (578).jpg: 640x576 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1702).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1124).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2224).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (769).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (648).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (50).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (249).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1824).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1186).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (92).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1982).jpg: 480x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (394).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2164).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1630).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2003).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1809).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (32).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (71).jpg: 448x640 1 face, 9.9ms\n",
      "Speed: 0.3ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1762).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1914).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1388).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (701).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2387).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (710).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1425).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1260).jpg: 640x608 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1420).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (372).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (660).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (324).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (40).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (508).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2476).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1955).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (454).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (284).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2023).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1776).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1644).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1621).jpg: 544x640 1 face, 13.2ms\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (600).jpg: 576x640 (no detections), 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2117).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1534).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2059).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (980).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (358).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2037).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (267).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2326).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (295).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2044).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1950).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (329).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1976).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (108).jpg: 640x480 1 face, 10.3ms\n",
      "Speed: 0.4ms preprocess, 10.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (909).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1328).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1880).jpg: 640x608 2 faces, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1930).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1559).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2480).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (91).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (164).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (363).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (659).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (419).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1681).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (56).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (640).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1107).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1598).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (416).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (976).jpg: 416x640 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1881).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1637).jpg: 640x544 2 faces, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2312).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (999).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2234).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1710).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (888).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (908).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2352).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (64).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1636).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2074).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1269).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (754).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2402).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1997).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1291).jpg: 640x448 1 face, 12.5ms\n",
      "Speed: 0.5ms preprocess, 12.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1352).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1013).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1140).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2099).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (925).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (918).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.1ms preprocess, 13.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1573).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (69).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (811).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (197).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2053).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1643).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1693).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1545).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2367).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2061).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (571).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1739).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1346).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (345).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2229).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2231).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1517).jpg: 640x640 2 faces, 12.8ms\n",
      "Speed: 0.3ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1528).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1649).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1402).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (772).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1629).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2220).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (814).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2400).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1986).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (714).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1182).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1405).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1998).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1942).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (430).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (779).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1823).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2232).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (154).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (2187).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (1651).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/0/0 (371).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (7).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (197).jpg: 640x512 2 faces, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (642).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1239).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (233).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1562).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2652).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (627).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1578).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (778).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1044).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1885).jpg: 640x416 2 faces, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2417).jpg: 640x448 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1838).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (357).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1968).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (102).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (827).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2637).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2650).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (162).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2420).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (792).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1240).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1734).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2244).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1097).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2437).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1285).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (706).jpg: 640x448 2 faces, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2604).jpg: 640x448 (no detections), 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2031).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2138).jpg: 640x576 (no detections), 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1787).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.3ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (180).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2083).jpg: 608x640 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (408).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1369).jpg: 640x384 1 face, 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2566).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2276).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2250).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (877).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (740).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1479).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1542).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (483).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (5).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (453).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1111).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1250).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1308).jpg: 640x416 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (142).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (569).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2547).jpg: 640x448 2 faces, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2246).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2607).jpg: 640x448 (no detections), 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (205).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1447).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (258).jpg: 640x512 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2565).jpg: 640x576 (no detections), 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (644).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (726).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1564).jpg: 640x512 (no detections), 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (43).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1689).jpg: 640x416 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (585).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (702).jpg: 640x480 3 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2277).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (981).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2635).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1134).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (923).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1114).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1493).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1600).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1850).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (553).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (480).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (711).jpg: 640x448 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (835).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (938).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1960).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (128).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1979).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (340).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1359).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (528).jpg: 640x448 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (47).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1032).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2525).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (211).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1744).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1927).jpg: 640x448 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1691).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (423).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (421).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1654).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (537).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2549).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (531).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (790).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2208).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (427).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1777).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (106).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1878).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1563).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (594).jpg: 544x640 (no detections), 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1914).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2085).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (403).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (40).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2243).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (343).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1955).jpg: 608x640 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (620).jpg: 640x416 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1529).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (210).jpg: 640x544 1 face, 12.8ms\n",
      "Speed: 0.1ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1421).jpg: 480x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2151).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (857).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (521).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1333).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2342).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (850).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (334).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1416).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (825).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2331).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (663).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1817).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1079).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (34).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2314).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (19).jpg: 640x640 (no detections), 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (611).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2306).jpg: 640x512 (no detections), 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (252).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2501).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (66).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1541).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2104).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2260).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1423).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1022).jpg: 640x448 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2320).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2512).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2442).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1732).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (836).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2290).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (538).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (225).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (784).jpg: 480x640 (no detections), 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1223).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1703).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (11).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1063).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (297).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2551).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2254).jpg: 640x608 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1055).jpg: 640x416 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (722).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2264).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (498).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1440).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1316).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2534).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1348).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2280).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (459).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1198).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1825).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (773).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1688).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2426).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1127).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1764).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1761).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2312).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (377).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1721).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1628).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2374).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2493).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1863).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1291).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2561).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2006).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1327).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2130).jpg: 640x384 1 face, 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1666).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2567).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (482).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1124).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (325).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (607).jpg: 640x448 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1517).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1397).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (738).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1618).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1507).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1958).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2348).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1701).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1085).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2542).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1067).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2297).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (488).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1961).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2470).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.3ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1625).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (148).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (705).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2528).jpg: 640x416 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (745).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1042).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (693).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1737).jpg: 640x448 (no detections), 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (391).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (592).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (80).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (201).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2335).jpg: 640x640 1 face, 13.0ms\n",
      "Speed: 0.2ms preprocess, 13.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2539).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1314).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2564).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1003).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (832).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2003).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (978).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1211).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (821).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2443).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1902).jpg: 544x640 1 face, 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (221).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2646).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1020).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (787).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (763).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1915).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1237).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (524).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (757).jpg: 640x416 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (925).jpg: 640x416 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1414).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (332).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (526).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1192).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (720).jpg: 480x640 1 face, 9.8ms\n",
      "Speed: 0.3ms preprocess, 9.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (171).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1512).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (506).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (917).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1657).jpg: 640x448 3 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1610).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (974).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (799).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (939).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1330).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2393).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1147).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (675).jpg: 640x448 3 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1587).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2425).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1153).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (402).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (511).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (115).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1694).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1441).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (275).jpg: 640x416 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2472).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1307).jpg: 640x416 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1575).jpg: 640x448 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (529).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (316).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (560).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.1ms preprocess, 13.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (676).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2504).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1008).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1499).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2636).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1719).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1010).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1999).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1936).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1803).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2559).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (328).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (735).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1360).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.3ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1612).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1157).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1456).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2236).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1756).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (41).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (931).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1468).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2164).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1776).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (876).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1816).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1144).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1154).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1857).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2591).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1576).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1179).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2422).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1964).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1900).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (375).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (959).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2010).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (797).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2143).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1768).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (223).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (407).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1451).jpg: 640x512 (no detections), 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1560).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2459).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2111).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2416).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2498).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2291).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2088).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1989).jpg: 640x512 (no detections), 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2593).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2610).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1511).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1581).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1849).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1664).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1205).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1821).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2362).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (486).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1275).jpg: 640x576 1 face, 13.7ms\n",
      "Speed: 0.3ms preprocess, 13.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1257).jpg: 640x448 1 face, 9.7ms\n",
      "Speed: 0.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1651).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2303).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (751).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (546).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2596).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2021).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (677).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (756).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1025).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1898).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1306).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1425).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (781).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (217).jpg: 640x384 1 face, 8.3ms\n",
      "Speed: 0.1ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1845).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (103).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2526).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (532).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (97).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2452).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2311).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2351).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2037).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (471).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2430).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2103).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (113).jpg: 544x640 1 face, 13.3ms\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1357).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2440).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (793).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (465).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2308).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1475).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2310).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1096).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (484).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2270).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (286).jpg: 640x448 (no detections), 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (724).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (848).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (305).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (703).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1412).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1526).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (214).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1172).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2137).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (753).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1113).jpg: 640x416 1 face, 9.8ms\n",
      "Speed: 0.3ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (867).jpg: 640x608 1 face, 13.8ms\n",
      "Speed: 0.1ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1778).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2240).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (170).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (155).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1046).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (882).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (946).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2273).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (248).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (806).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2271).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (122).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1767).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2125).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1521).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2071).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2096).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (206).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1881).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2191).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (235).jpg: 640x512 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (144).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2098).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (920).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (132).jpg: 640x416 2 faces, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (996).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1310).jpg: 640x448 (no detections), 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2168).jpg: 640x448 2 faces, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2456).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (879).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (617).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1366).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (899).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1907).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2552).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1824).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1065).jpg: 608x640 1 face, 14.1ms\n",
      "Speed: 0.3ms preprocess, 14.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1820).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (783).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (18).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2080).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1061).jpg: 640x608 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (588).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2588).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2007).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (623).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2176).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (656).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (859).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1197).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2129).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (288).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2207).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1260).jpg: 640x352 1 face, 8.2ms\n",
      "Speed: 0.1ms preprocess, 8.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (413).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2469).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1558).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1853).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1093).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2233).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (808).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1513).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (63).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (819).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1606).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (472).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (467).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1088).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1763).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2654).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1769).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1280).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2274).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2366).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (152).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1444).jpg: 640x512 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2403).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2322).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1455).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1765).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (551).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1244).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1641).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2023).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (346).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1539).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1161).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1142).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1104).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.3ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (213).jpg: 512x640 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2288).jpg: 608x640 (no detections), 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (636).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (406).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1895).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2245).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2583).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1270).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (699).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2101).jpg: 640x512 1 face, 8.8ms\n",
      "Speed: 0.3ms preprocess, 8.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1058).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2211).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (643).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2036).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2557).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (586).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1859).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (962).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2328).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (573).jpg: 608x640 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1665).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (284).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1846).jpg: 640x448 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2030).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1232).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (287).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1231).jpg: 640x416 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1730).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1129).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2093).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (478).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1497).jpg: 640x640 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (241).jpg: 384x640 (no detections), 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (613).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1724).jpg: 640x448 (no detections), 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (958).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (190).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1266).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1926).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (525).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1368).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2249).jpg: 640x416 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1561).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2005).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2115).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (265).jpg: 640x448 2 faces, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (138).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1066).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (947).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2060).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2544).jpg: 640x480 1 face, 14.0ms\n",
      "Speed: 0.5ms preprocess, 14.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1692).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2387).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1267).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2039).jpg: 640x448 3 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2140).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1714).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1049).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1579).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2075).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2235).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (394).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2063).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2370).jpg: 640x448 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1819).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2535).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1100).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1875).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2266).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (400).jpg: 640x416 1 face, 11.5ms\n",
      "Speed: 0.1ms preprocess, 11.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2428).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2206).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (840).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (254).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1361).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1873).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (296).jpg: 640x480 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2369).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1667).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1847).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1458).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1309).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (873).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1842).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (987).jpg: 640x544 2 faces, 13.0ms\n",
      "Speed: 0.4ms preprocess, 13.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (872).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (956).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2032).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1326).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1125).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (350).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1839).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2062).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2165).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2253).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (509).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2073).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (909).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1036).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1394).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (669).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1000).jpg: 640x480 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2121).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (174).jpg: 640x416 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1021).jpg: 640x544 (no detections), 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1550).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2079).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (815).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2389).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (847).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (687).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1137).jpg: 640x480 (no detections), 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1341).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.3ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1389).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1465).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1970).jpg: 640x576 1 face, 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (727).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (380).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (775).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (765).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (347).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2223).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2336).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1952).jpg: 640x448 2 faces, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (263).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (412).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1884).jpg: 640x352 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1452).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2092).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2603).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (824).jpg: 640x448 (no detections), 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1262).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (123).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (596).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (843).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (131).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1963).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1681).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1399).jpg: 640x544 1 face, 12.4ms\n",
      "Speed: 0.2ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (96).jpg: 640x480 (no detections), 10.6ms\n",
      "Speed: 0.2ms preprocess, 10.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2142).jpg: 640x512 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1522).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1297).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1001).jpg: 640x512 (no detections), 9.9ms\n",
      "Speed: 0.4ms preprocess, 9.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (57).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2474).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1870).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2612).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1630).jpg: 640x352 1 face, 8.3ms\n",
      "Speed: 0.1ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1276).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1053).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1634).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (602).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2439).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2343).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2110).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1686).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (14).jpg: 640x544 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2409).jpg: 544x640 1 face, 13.2ms\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (52).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1658).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (599).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2174).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1789).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (566).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (445).jpg: 640x448 (no detections), 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2468).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.1ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (970).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1791).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2262).jpg: 640x416 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2126).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2617).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1027).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2487).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1810).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1430).jpg: 640x608 (no detections), 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2527).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1429).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (276).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2289).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (384).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (744).jpg: 640x416 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2170).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (98).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1808).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2611).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1335).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2299).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1680).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (928).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (329).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1978).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (17).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1598).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (460).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2019).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (655).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (182).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1191).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2461).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1005).jpg: 640x384 1 face, 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2555).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (16).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2198).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1396).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (54).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2385).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1582).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (42).jpg: 640x416 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (396).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2152).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2317).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2095).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (686).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1041).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1585).jpg: 320x640 1 face, 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2522).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1279).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (333).jpg: 640x448 2 faces, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (156).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (640).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1264).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2390).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (363).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (927).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1760).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1336).jpg: 640x576 (no detections), 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1655).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (139).jpg: 640x512 (no detections), 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1039).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (754).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1893).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1773).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2339).jpg: 416x640 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (301).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2449).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1238).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (371).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1087).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1632).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2251).jpg: 640x640 1 face, 13.1ms\n",
      "Speed: 0.4ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (192).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (322).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (160).jpg: 640x544 1 face, 12.4ms\n",
      "Speed: 0.1ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (364).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1780).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2338).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1716).jpg: 640x512 (no detections), 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1165).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (977).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (683).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1584).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (746).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1463).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2415).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (231).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1467).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2423).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1224).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2344).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2568).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1107).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1024).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1139).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2451).jpg: 544x640 (no detections), 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1840).jpg: 640x640 (no detections), 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1372).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1851).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (392).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (689).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2481).jpg: 640x608 (no detections), 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (814).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (638).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1889).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1829).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1781).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1949).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.3ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1947).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (555).jpg: 640x384 1 face, 8.3ms\n",
      "Speed: 0.1ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1559).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1969).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1407).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.1ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2258).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2185).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (365).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (944).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2124).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1086).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (982).jpg: 640x448 3 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1268).jpg: 640x480 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1929).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1711).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1350).jpg: 640x640 (no detections), 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (198).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1028).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2171).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2381).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2183).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (606).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (650).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (779).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1338).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1485).jpg: 640x416 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1762).jpg: 640x448 2 faces, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2353).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1492).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (826).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (222).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2585).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (788).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2510).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (196).jpg: 416x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2267).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1933).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (758).jpg: 640x448 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2281).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1068).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (304).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1515).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (898).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (919).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (299).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (444).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2399).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (701).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2360).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2517).jpg: 640x512 (no detections), 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (548).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.3ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1325).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (892).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1633).jpg: 512x640 (no detections), 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (993).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1166).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (865).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (353).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (149).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1860).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (905).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1026).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2034).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (302).jpg: 640x480 1 face, 10.7ms\n",
      "Speed: 0.5ms preprocess, 10.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1167).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1722).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2202).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1713).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2515).jpg: 640x448 2 faces, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2132).jpg: 640x512 (no detections), 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (448).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1617).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (439).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (657).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2231).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1344).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (232).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1069).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (900).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1135).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (145).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (615).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2619).jpg: 640x416 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1800).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (995).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2644).jpg: 640x416 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (760).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2216).jpg: 640x512 (no detections), 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (838).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1815).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (308).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (492).jpg: 640x384 1 face, 8.3ms\n",
      "Speed: 0.1ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1624).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (463).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (264).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1882).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (794).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1185).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (884).jpg: 544x640 1 face, 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (388).jpg: 352x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1200).jpg: 640x512 2 faces, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1786).jpg: 640x448 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1248).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1091).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (65).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1811).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (550).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2232).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (595).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1274).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (317).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2074).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1504).jpg: 544x640 1 face, 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1988).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1222).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1230).jpg: 640x544 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1622).jpg: 640x544 1 face, 12.4ms\n",
      "Speed: 0.2ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (159).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (220).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1524).jpg: 544x640 (no detections), 13.1ms\n",
      "Speed: 0.1ms preprocess, 13.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1583).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2648).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2043).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1653).jpg: 640x384 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (866).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (415).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2624).jpg: 544x640 (no detections), 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1074).jpg: 640x416 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2455).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1991).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (930).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (574).jpg: 640x352 1 face, 8.3ms\n",
      "Speed: 0.1ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1173).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1642).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (15).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (743).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (469).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (870).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (134).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1328).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (420).jpg: 640x512 1 face, 9.2ms\n",
      "Speed: 0.3ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1119).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (712).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (259).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (56).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2357).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (749).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (736).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1203).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1054).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (425).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1075).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2606).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (513).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1464).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (541).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (968).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (438).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2432).jpg: 640x544 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (92).jpg: 288x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1466).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1993).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1358).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1062).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1731).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1712).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1735).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1901).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1453).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2424).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (601).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1673).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1910).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2024).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2307).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1199).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2283).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (219).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1315).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1879).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2355).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (709).jpg: 640x480 1 face, 10.1ms\n",
      "Speed: 0.4ms preprocess, 10.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1174).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2628).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1488).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1501).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1802).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1033).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (411).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1178).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (473).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2410).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2301).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (679).jpg: 640x416 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (362).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2090).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1477).jpg: 544x640 1 face, 13.2ms\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1536).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2395).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.4ms preprocess, 12.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (591).jpg: 640x640 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (295).jpg: 640x640 (no detections), 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (992).jpg: 640x640 (no detections), 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2508).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1921).jpg: 640x416 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (447).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1809).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2011).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1077).jpg: 640x512 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2347).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2578).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2109).jpg: 640x416 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (499).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.1ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1953).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (281).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1047).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (817).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (830).jpg: 640x480 (no detections), 9.6ms\n",
      "Speed: 0.3ms preprocess, 9.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (609).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (199).jpg: 640x416 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2658).jpg: 480x640 (no detections), 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2413).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (818).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1132).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1595).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2302).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (181).jpg: 640x512 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (409).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1190).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (33).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1162).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1794).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1106).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.3ms preprocess, 12.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2494).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1406).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2000).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (312).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1105).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1920).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (659).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.1ms preprocess, 13.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1971).jpg: 480x640 (no detections), 9.6ms\n",
      "Speed: 0.1ms preprocess, 9.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (759).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (141).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1928).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (393).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2118).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1252).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2460).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2187).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (951).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2326).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1676).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (534).jpg: 544x640 1 face, 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1356).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (491).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1428).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2530).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (941).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1473).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2378).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1974).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2069).jpg: 640x480 (no detections), 10.0ms\n",
      "Speed: 0.3ms preprocess, 10.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (143).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1796).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (953).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2545).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1148).jpg: 640x352 1 face, 8.3ms\n",
      "Speed: 0.1ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (481).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2407).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2136).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1009).jpg: 640x448 1 face, 12.6ms\n",
      "Speed: 0.3ms preprocess, 12.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1265).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (598).jpg: 640x512 (no detections), 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (888).jpg: 640x416 1 face, 9.6ms\n",
      "Speed: 0.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1374).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1538).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1822).jpg: 640x544 (no detections), 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (880).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1779).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (124).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1168).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (739).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (955).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1102).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1177).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (395).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2630).jpg: 640x512 (no detections), 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2506).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1795).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (240).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (185).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1662).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (501).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (587).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1376).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1071).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (767).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (76).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2309).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1944).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (133).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (904).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (935).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1321).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (913).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1469).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1443).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1782).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1520).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (950).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (86).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (508).jpg: 640x576 (no detections), 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (633).jpg: 640x416 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1363).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (390).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (89).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (77).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (527).jpg: 640x352 1 face, 8.3ms\n",
      "Speed: 0.1ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1594).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (310).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2540).jpg: 640x448 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1216).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1484).jpg: 480x640 1 face, 9.7ms\n",
      "Speed: 0.2ms preprocess, 9.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1748).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (523).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2225).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (37).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1155).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (237).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1683).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2380).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (774).jpg: 640x608 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1092).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1405).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1807).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (67).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (558).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1415).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1917).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1478).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1543).jpg: 640x448 (no detections), 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (846).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1937).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1586).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1263).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (571).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (887).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2586).jpg: 640x448 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2153).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2489).jpg: 640x448 (no detections), 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2383).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1980).jpg: 640x448 2 faces, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1545).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2053).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1305).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2201).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1427).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1679).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1183).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (967).jpg: 544x640 (no detections), 13.2ms\n",
      "Speed: 0.2ms preprocess, 13.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (721).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2598).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1772).jpg: 640x448 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1384).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1133).jpg: 640x576 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2119).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2609).jpg: 512x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (670).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1487).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1292).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (245).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1533).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (336).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.1ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2465).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (290).jpg: 544x640 (no detections), 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (841).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1196).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1445).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1064).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (575).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (452).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1349).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (632).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1591).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1116).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (583).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1300).jpg: 416x640 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (324).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (786).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (356).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2513).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (485).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1596).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1930).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (44).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1319).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1516).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1146).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1862).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1171).jpg: 640x480 2 faces, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (581).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (354).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1170).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2601).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (762).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (926).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1766).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2391).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2618).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (837).jpg: 640x416 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1186).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.1ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2436).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (36).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1702).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1577).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1589).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (244).jpg: 640x512 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1235).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1098).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1623).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1351).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2368).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1571).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (378).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2048).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (672).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (518).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1844).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2068).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.3ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (169).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1663).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2227).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2623).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (495).jpg: 640x640 2 faces, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (742).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1939).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1552).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (539).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2340).jpg: 640x544 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (442).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1956).jpg: 640x448 3 faces, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (30).jpg: 640x480 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2135).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2285).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (823).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (342).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1613).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2295).jpg: 640x480 2 faces, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (470).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1741).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1941).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2345).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2087).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (60).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (772).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.3ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (714).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1434).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2659).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (306).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1874).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (893).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1717).jpg: 448x640 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2084).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (426).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1059).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1014).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (649).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1060).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2017).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1446).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2329).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1669).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1784).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (654).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (911).jpg: 640x352 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1548).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2427).jpg: 320x640 1 face, 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1241).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1818).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1668).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1546).jpg: 544x640 (no detections), 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1354).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (183).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2247).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1371).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (795).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1402).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1725).jpg: 640x544 1 face, 12.4ms\n",
      "Speed: 0.2ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1924).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1855).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1495).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2482).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1176).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1390).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1684).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2595).jpg: 640x448 1 face, 13.0ms\n",
      "Speed: 0.5ms preprocess, 13.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1188).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1981).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.3ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1992).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1449).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (319).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (9).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2228).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2324).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2278).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1629).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1977).jpg: 448x640 1 face, 9.7ms\n",
      "Speed: 0.3ms preprocess, 9.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (634).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1827).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2313).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (803).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1659).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1611).jpg: 640x480 1 face, 9.7ms\n",
      "Speed: 0.4ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (191).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (414).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (204).jpg: 480x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (624).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (46).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1909).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2127).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1080).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1123).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (436).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (990).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (24).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1535).jpg: 640x352 1 face, 8.3ms\n",
      "Speed: 0.1ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (161).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (327).jpg: 640x640 (no detections), 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2148).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (943).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1962).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2429).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2382).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (715).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1911).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (761).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2013).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2133).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (932).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1295).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1906).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (578).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1320).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1391).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1886).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2052).jpg: 640x512 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2086).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1627).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2252).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2287).jpg: 544x640 (no detections), 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1052).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2332).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2570).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2042).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (262).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (710).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (646).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2462).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2641).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (768).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2204).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2041).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (579).jpg: 640x480 (no detections), 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (502).jpg: 640x512 2 faces, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1556).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2625).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2070).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (88).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1101).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1160).jpg: 608x640 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (119).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (175).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (590).jpg: 640x544 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1322).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (915).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1393).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (497).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (625).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (434).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1695).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1007).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1082).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1880).jpg: 640x352 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1103).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (766).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1500).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1017).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (811).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2272).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (914).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (229).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (514).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2521).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2091).jpg: 640x608 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1189).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1317).jpg: 640x448 1 face, 9.7ms\n",
      "Speed: 0.3ms preprocess, 9.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1180).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (72).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (224).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1607).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1888).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (630).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2330).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (78).jpg: 640x448 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1951).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1271).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1648).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1201).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1120).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1016).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2627).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1531).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1149).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2571).jpg: 512x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1932).jpg: 544x640 1 face, 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (520).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1896).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (335).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1480).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (570).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.3ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (418).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2645).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (93).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (831).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1481).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1899).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (604).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2105).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1636).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1904).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1852).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2173).jpg: 640x416 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2581).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (120).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (901).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (776).jpg: 640x480 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1448).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (875).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2480).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2592).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (55).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1640).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1380).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (352).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (791).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1303).jpg: 640x480 2 faces, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2196).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1945).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (809).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (238).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1894).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (535).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (70).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1833).jpg: 480x640 1 face, 9.8ms\n",
      "Speed: 0.2ms preprocess, 9.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (805).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (202).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1733).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1436).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (379).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2466).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2401).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2116).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2210).jpg: 640x448 3 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (186).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1002).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.3ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2296).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2239).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1567).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1083).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (796).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2384).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (249).jpg: 640x384 1 face, 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (410).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (829).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (154).jpg: 640x576 (no detections), 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1697).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2002).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1420).jpg: 640x416 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2057).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1644).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (614).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1593).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1301).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2064).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2269).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2319).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2217).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1030).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (127).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (158).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2001).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1181).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1590).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2367).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1573).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (38).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1959).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2454).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1867).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1705).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (430).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2434).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (812).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2215).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (330).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1601).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (748).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1743).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (878).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1502).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1311).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1234).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (58).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1675).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (349).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1013).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1193).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (289).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1489).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (203).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (313).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1246).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (750).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1597).jpg: 640x448 1 face, 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1159).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.3ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (616).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1843).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1660).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2180).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1184).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (861).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1156).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (770).jpg: 640x512 (no detections), 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (626).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1089).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1404).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (309).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2163).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2546).jpg: 640x416 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2120).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1462).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1141).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (507).jpg: 640x384 1 face, 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1925).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1084).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (285).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1626).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (247).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1670).jpg: 640x448 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (816).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (864).jpg: 480x640 (no detections), 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (664).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (704).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (74).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1619).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (661).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1708).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1525).jpg: 640x448 3 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1742).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2584).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1729).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (997).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (193).jpg: 640x608 (no detections), 13.9ms\n",
      "Speed: 0.3ms preprocess, 13.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1482).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1072).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1638).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (429).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1037).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (833).jpg: 640x480 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2574).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (645).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (79).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2590).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1547).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2028).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (443).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (769).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1738).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1038).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (945).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2172).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.3ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1040).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (716).jpg: 448x640 2 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (358).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2580).jpg: 640x544 2 faces, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (522).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (771).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1381).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1835).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1707).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (326).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2633).jpg: 640x448 (no detections), 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2537).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1877).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (381).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2514).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1798).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1212).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2490).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (741).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (562).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2134).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (860).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (433).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.1ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (48).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2112).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (176).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (29).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1076).jpg: 640x544 1 face, 12.4ms\n",
      "Speed: 0.2ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1472).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (902).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (976).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1908).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2634).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2477).jpg: 640x480 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1110).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1204).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1012).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2475).jpg: 640x576 1 face, 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (565).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (916).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2046).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (600).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1723).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1616).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (542).jpg: 640x448 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (10).jpg: 640x544 1 face, 13.0ms\n",
      "Speed: 0.2ms preprocess, 13.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2315).jpg: 640x512 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (733).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1460).jpg: 640x448 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2441).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (104).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (949).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2509).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1004).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2265).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1051).jpg: 640x384 1 face, 8.3ms\n",
      "Speed: 0.1ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2167).jpg: 640x608 (no detections), 14.2ms\n",
      "Speed: 0.2ms preprocess, 14.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (503).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (777).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2476).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (658).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2486).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (300).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (500).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1138).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (216).jpg: 640x608 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1143).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (554).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2354).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2463).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (243).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (973).jpg: 640x480 (no detections), 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1377).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2014).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1631).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2337).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1494).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (505).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (856).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2150).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.3ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1095).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2050).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1050).jpg: 640x448 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1043).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2533).jpg: 640x448 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (886).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.3ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1229).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2352).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (696).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1967).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (493).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1128).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (963).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1996).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2495).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (728).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1339).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1752).jpg: 640x416 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (45).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2538).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (404).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1255).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1408).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (936).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (515).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (536).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1140).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1287).jpg: 640x416 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (869).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1490).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (150).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2496).jpg: 640x640 1 face, 13.9ms\n",
      "Speed: 0.6ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1771).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1367).jpg: 512x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (807).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (871).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1208).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1365).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (952).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1555).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2541).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2067).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2026).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (647).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (517).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (908).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2147).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1976).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2577).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (468).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (422).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2447).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2199).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2226).jpg: 480x640 (no detections), 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1130).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2485).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1187).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (226).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (207).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (665).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1435).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.3ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2359).jpg: 640x544 1 face, 12.8ms\n",
      "Speed: 0.3ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1609).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (474).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1549).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (651).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2177).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1966).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (557).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1439).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1483).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (370).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1975).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (567).jpg: 640x448 1 face, 9.8ms\n",
      "Speed: 0.4ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1432).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1739).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1869).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (269).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (373).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1774).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1954).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2237).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1518).jpg: 640x448 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2356).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (858).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2081).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2484).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (147).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2572).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1916).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (688).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2218).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1433).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1298).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1438).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1646).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1112).jpg: 640x640 (no detections), 13.0ms\n",
      "Speed: 0.3ms preprocess, 13.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1693).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1972).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (294).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1312).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2082).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1770).jpg: 640x448 (no detections), 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (230).jpg: 640x512 2 faces, 9.4ms\n",
      "Speed: 0.4ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1856).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (12).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (540).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1985).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (153).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1215).jpg: 512x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (891).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1118).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (730).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (278).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (215).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2379).jpg: 544x640 1 face, 13.1ms\n",
      "Speed: 0.1ms preprocess, 13.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2536).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1251).jpg: 640x448 1 face, 9.6ms\n",
      "Speed: 0.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1872).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2205).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2061).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (13).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1965).jpg: 640x448 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2255).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (685).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (399).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1503).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1289).jpg: 640x480 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2597).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (580).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (986).jpg: 544x640 1 face, 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1614).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2209).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2316).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (100).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1006).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1090).jpg: 640x512 (no detections), 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2213).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1854).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (109).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2284).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (635).jpg: 640x384 1 face, 8.5ms\n",
      "Speed: 0.1ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (593).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (157).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (366).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1700).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (172).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (971).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.1ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2220).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1392).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (28).jpg: 640x480 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (85).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2197).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2275).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (253).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.3ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2453).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1572).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (271).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1826).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (282).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1508).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2186).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1602).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (680).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1424).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2318).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (822).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (603).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1509).jpg: 640x576 1 face, 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (121).jpg: 640x448 1 face, 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (477).jpg: 640x448 1 face, 10.0ms\n",
      "Speed: 0.4ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2364).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1346).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1375).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2372).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2035).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (6).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1718).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (552).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2193).jpg: 640x480 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (906).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (291).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1990).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (369).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1620).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (112).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (270).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2371).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1757).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1661).jpg: 640x544 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (957).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2263).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (718).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (446).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2009).jpg: 288x640 1 face, 8.6ms\n",
      "Speed: 0.2ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1506).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1454).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2222).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (547).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (212).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1332).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2066).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2365).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1383).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2259).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1194).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1903).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1685).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (184).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (991).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2397).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2587).jpg: 640x416 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1413).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1078).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (81).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1206).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2492).jpg: 640x448 1 face, 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (62).jpg: 640x448 (no detections), 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1210).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1117).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2543).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2450).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2386).jpg: 640x416 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2056).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2190).jpg: 448x640 2 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (165).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1805).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2282).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (673).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2446).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1277).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1388).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2473).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1256).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1710).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (456).jpg: 640x352 1 face, 8.3ms\n",
      "Speed: 0.1ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (337).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (985).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2159).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1293).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (998).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (545).jpg: 640x416 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (437).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (303).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (279).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2294).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2656).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.3ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (719).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1682).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (428).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2257).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (934).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (398).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (431).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (462).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1313).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (897).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1245).jpg: 640x416 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1793).jpg: 608x640 (no detections), 14.0ms\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2077).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (668).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (68).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1126).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (389).jpg: 544x640 1 face, 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (490).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (937).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (883).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1227).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2408).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (163).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1329).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (82).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (355).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (53).jpg: 480x640 1 face, 9.8ms\n",
      "Speed: 0.2ms preprocess, 9.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1532).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (168).jpg: 640x576 (no detections), 13.6ms\n",
      "Speed: 0.1ms preprocess, 13.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (682).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2655).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1182).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2286).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2304).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1892).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2599).jpg: 640x416 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (475).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (250).jpg: 640x544 1 face, 12.4ms\n",
      "Speed: 0.2ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (31).jpg: 640x544 1 face, 12.4ms\n",
      "Speed: 0.2ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2448).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2242).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1615).jpg: 448x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (910).jpg: 640x640 1 face, 13.0ms\n",
      "Speed: 0.4ms preprocess, 13.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1471).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1861).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1621).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (307).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1983).jpg: 448x640 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (25).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1569).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (933).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (32).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (283).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2483).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (845).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1987).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1540).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2327).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2518).jpg: 640x416 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2358).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2161).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (51).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (167).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (348).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (449).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1986).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.3ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1403).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1647).jpg: 640x448 (no detections), 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2341).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.3ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2055).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (494).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (189).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.1ms preprocess, 12.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (984).jpg: 416x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1715).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (479).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (331).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2562).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (83).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (729).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (338).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (972).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1220).jpg: 640x640 1 face, 13.0ms\n",
      "Speed: 0.3ms preprocess, 13.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (266).jpg: 640x576 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1832).jpg: 640x352 1 face, 8.3ms\n",
      "Speed: 0.2ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (487).jpg: 640x416 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2128).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2503).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1876).jpg: 480x640 (no detections), 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2406).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (785).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2405).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2651).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (582).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1871).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1568).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (921).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (273).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (461).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2575).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1923).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2615).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (605).jpg: 608x640 (no detections), 14.0ms\n",
      "Speed: 0.2ms preprocess, 14.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2333).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (975).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2418).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1228).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2230).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1995).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (780).jpg: 640x640 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1378).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2076).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1217).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2398).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1812).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2323).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2261).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (292).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2404).jpg: 640x512 1 face, 11.4ms\n",
      "Speed: 0.3ms preprocess, 11.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2524).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2402).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2027).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2300).jpg: 608x640 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2049).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (257).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2141).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2412).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2523).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2131).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2647).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1340).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (27).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1728).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1385).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2642).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (694).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (234).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2550).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2100).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2200).jpg: 640x448 3 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (849).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1373).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2018).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1592).jpg: 640x448 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (320).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1848).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1362).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.3ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (929).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2122).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1523).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1753).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (851).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2015).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (621).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (731).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2532).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1242).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (737).jpg: 640x448 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2657).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2433).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2268).jpg: 640x448 3 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1736).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2411).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (464).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (723).jpg: 384x640 1 face, 8.6ms\n",
      "Speed: 0.1ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (228).jpg: 640x576 1 face, 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1015).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2054).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (114).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2029).jpg: 384x640 (no detections), 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2229).jpg: 640x640 1 face, 13.0ms\n",
      "Speed: 0.3ms preprocess, 13.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1318).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (200).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (862).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1935).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (218).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (385).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1797).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1164).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (801).jpg: 640x352 1 face, 8.3ms\n",
      "Speed: 0.1ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (256).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (87).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (619).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (691).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2608).jpg: 640x576 (no detections), 13.6ms\n",
      "Speed: 0.1ms preprocess, 13.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1302).jpg: 640x640 2 faces, 13.0ms\n",
      "Speed: 0.4ms preprocess, 13.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2653).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1207).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1897).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1553).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2622).jpg: 640x448 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (49).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (4).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (367).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1247).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2560).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2051).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1175).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (39).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.3ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1035).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (476).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2505).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2044).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2594).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1674).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2212).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1530).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1720).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2392).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2554).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (834).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2579).jpg: 640x608 (no detections), 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (345).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (653).jpg: 640x544 1 face, 12.4ms\n",
      "Speed: 0.2ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2038).jpg: 640x512 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1806).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (890).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (268).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2511).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (725).jpg: 640x416 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (440).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (130).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (512).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (589).jpg: 640x448 1 face, 10.2ms\n",
      "Speed: 0.3ms preprocess, 10.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (405).jpg: 640x608 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (681).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (208).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (59).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1281).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.3ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1998).jpg: 640x416 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1603).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2123).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (496).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2529).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1382).jpg: 384x640 1 face, 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (91).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1410).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1019).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2241).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1474).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (789).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2602).jpg: 640x416 (no detections), 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1973).jpg: 640x512 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1011).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (896).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2214).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1887).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2643).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1866).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (22).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (117).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2203).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2033).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2325).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1347).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1940).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1213).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2155).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2189).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (489).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1758).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1284).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (227).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1299).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1323).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1169).jpg: 512x640 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2376).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1214).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (108).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (549).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2169).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2160).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1749).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1470).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1294).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1754).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1150).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2117).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2516).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1799).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (544).jpg: 640x448 1 face, 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1566).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (386).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1834).jpg: 512x640 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2621).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (64).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2114).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (73).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1706).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (99).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1828).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1272).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2175).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1801).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1913).jpg: 640x480 3 faces, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (979).jpg: 640x448 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (236).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (881).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (561).jpg: 640x384 1 face, 8.3ms\n",
      "Speed: 0.1ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1258).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1637).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1865).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1023).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1922).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2616).jpg: 640x640 (no detections), 12.9ms\n",
      "Speed: 0.3ms preprocess, 12.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (318).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (798).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1792).jpg: 640x384 1 face, 8.3ms\n",
      "Speed: 0.1ms preprocess, 8.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1580).jpg: 640x512 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (960).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2144).jpg: 640x576 (no detections), 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2219).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1254).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (419).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2094).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.3ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (563).jpg: 320x640 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (782).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (178).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2113).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1045).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2396).jpg: 640x416 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1699).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2195).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1158).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (608).jpg: 640x512 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (424).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (8).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (885).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (852).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2022).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (637).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.3ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (516).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2361).jpg: 640x480 3 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2500).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (610).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2334).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (260).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1334).jpg: 640x416 1 face, 15.0ms\n",
      "Speed: 0.5ms preprocess, 15.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2435).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (692).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (21).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (988).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2421).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1813).jpg: 640x512 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1070).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1918).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1788).jpg: 640x512 (no detections), 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1195).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2556).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2457).jpg: 480x640 (no detections), 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2194).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1599).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1510).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (351).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2488).jpg: 640x352 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1750).jpg: 640x384 1 face, 8.6ms\n",
      "Speed: 0.2ms preprocess, 8.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2178).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2631).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2639).jpg: 608x640 (no detections), 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2089).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1073).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (942).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (361).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2248).jpg: 512x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (90).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2157).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1202).jpg: 544x640 1 face, 14.0ms\n",
      "Speed: 0.5ms preprocess, 14.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2181).jpg: 640x576 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1831).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (209).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1783).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (802).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (707).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2388).jpg: 640x448 1 face, 10.0ms\n",
      "Speed: 0.2ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2479).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (918).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (23).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (629).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (179).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1218).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (173).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (510).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (804).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (903).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1457).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1398).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (339).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1386).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2238).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1221).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (695).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (969).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (667).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1422).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1282).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (813).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2375).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1288).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2558).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1740).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (999).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1671).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (267).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2605).jpg: 640x576 (no detections), 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1273).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2102).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2491).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (844).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2184).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1942).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (315).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1122).jpg: 640x416 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (940).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2346).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2139).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (458).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (341).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1551).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2107).jpg: 640x640 1 face, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2502).jpg: 640x512 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1858).jpg: 640x448 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1486).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1687).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (146).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1537).jpg: 640x544 1 face, 12.8ms\n",
      "Speed: 0.1ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (662).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (698).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (572).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2156).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1709).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (994).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1491).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (690).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (277).jpg: 640x480 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (639).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1919).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1696).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (140).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (854).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1461).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1342).jpg: 640x608 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1943).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1411).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2192).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1018).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (584).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2626).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2221).jpg: 640x480 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1099).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (323).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1652).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1883).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1304).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2373).jpg: 640x352 1 face, 8.5ms\n",
      "Speed: 0.1ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (907).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (954).jpg: 608x640 1 face, 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (734).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (125).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1121).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1557).jpg: 480x640 (no detections), 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1364).jpg: 640x640 1 face, 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2400).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (839).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2520).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (576).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2025).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (435).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1426).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1442).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (50).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1496).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1868).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2614).jpg: 640x544 (no detections), 12.9ms\n",
      "Speed: 0.3ms preprocess, 12.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (671).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (280).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (961).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (20).jpg: 544x640 1 face, 13.1ms\n",
      "Speed: 0.1ms preprocess, 13.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (311).jpg: 640x448 2 faces, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (441).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2099).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2640).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (895).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2553).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1236).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (239).jpg: 512x640 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2072).jpg: 640x544 1 face, 13.0ms\n",
      "Speed: 0.2ms preprocess, 13.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1775).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1131).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (75).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (298).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (26).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (618).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1094).jpg: 640x640 1 face, 13.0ms\n",
      "Speed: 0.3ms preprocess, 13.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2419).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1678).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1081).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (559).jpg: 640x448 2 faces, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (717).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1650).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (983).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2108).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2377).jpg: 640x640 (no detections), 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2458).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1604).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1056).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (94).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2146).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2519).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2045).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2414).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (828).jpg: 480x640 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1437).jpg: 640x544 2 faces, 12.6ms\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (242).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1931).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (504).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2548).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2078).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2464).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (61).jpg: 416x640 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2363).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1574).jpg: 640x640 1 face, 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (359).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1261).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (556).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1331).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1034).jpg: 640x448 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1209).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2478).jpg: 640x512 2 faces, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1755).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1643).jpg: 448x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1649).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (612).jpg: 640x448 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (965).jpg: 448x640 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (126).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1286).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1690).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1400).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (95).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1957).jpg: 640x416 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (454).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1283).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1290).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2467).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (641).jpg: 640x448 1 face, 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1115).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (321).jpg: 640x416 (no detections), 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2573).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1225).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (314).jpg: 640x640 (no detections), 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2531).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (564).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (137).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1836).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (110).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (372).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2613).jpg: 640x640 (no detections), 13.2ms\n",
      "Speed: 0.5ms preprocess, 13.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (922).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (368).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (989).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (272).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1608).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (863).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1324).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1934).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1747).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (519).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (105).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.1ms preprocess, 9.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1379).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2620).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (457).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1337).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (697).jpg: 640x576 1 face, 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1534).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1519).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1841).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (416).jpg: 384x640 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (755).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1837).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (543).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1109).jpg: 640x544 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2600).jpg: 640x448 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1994).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (855).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1269).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (107).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1431).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1527).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2563).jpg: 640x544 1 face, 12.4ms\n",
      "Speed: 0.2ms preprocess, 12.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (135).jpg: 640x544 1 face, 12.5ms\n",
      "Speed: 0.2ms preprocess, 12.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1296).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (383).jpg: 640x640 1 face, 12.9ms\n",
      "Speed: 0.2ms preprocess, 12.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1476).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1656).jpg: 640x480 2 faces, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2047).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1029).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1830).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2224).jpg: 384x640 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1639).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (195).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2438).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1905).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1645).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (980).jpg: 640x608 (no detections), 13.9ms\n",
      "Speed: 0.2ms preprocess, 13.9ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (116).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (293).jpg: 640x448 2 faces, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (568).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (708).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1048).jpg: 384x640 (no detections), 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1544).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1565).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2569).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2497).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1417).jpg: 544x640 (no detections), 13.1ms\n",
      "Speed: 0.2ms preprocess, 13.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1401).jpg: 640x448 1 face, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1353).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (251).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (376).jpg: 640x576 (no detections), 13.5ms\n",
      "Speed: 0.1ms preprocess, 13.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (432).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (966).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1395).jpg: 640x448 2 faces, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2020).jpg: 640x448 2 faces, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (948).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2154).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (101).jpg: 640x448 1 face, 12.7ms\n",
      "Speed: 0.5ms preprocess, 12.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (129).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1946).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1677).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2431).jpg: 512x640 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1948).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1759).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2589).jpg: 384x640 (no detections), 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (194).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (533).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2292).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (69).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1345).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2097).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1108).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1355).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (274).jpg: 640x416 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2016).jpg: 640x416 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (401).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (360).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1528).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (387).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2065).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1343).jpg: 640x448 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2499).jpg: 512x640 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (874).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (810).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1459).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1891).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (684).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (894).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2293).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2582).jpg: 640x512 (no detections), 9.1ms\n",
      "Speed: 0.3ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2234).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.1ms preprocess, 8.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1419).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1814).jpg: 640x448 2 faces, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1352).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (397).jpg: 512x640 (no detections), 9.5ms\n",
      "Speed: 0.2ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (177).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1890).jpg: 640x512 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1982).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1698).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (924).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1672).jpg: 640x384 1 face, 8.5ms\n",
      "Speed: 0.2ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1219).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2305).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1226).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2576).jpg: 640x576 (no detections), 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2632).jpg: 640x640 1 face, 12.7ms\n",
      "Speed: 0.1ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1243).jpg: 640x448 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1570).jpg: 640x480 2 faces, 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1505).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2394).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (889).jpg: 640x640 (no detections), 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (450).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (648).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (374).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (530).jpg: 640x448 3 faces, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1554).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (853).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2507).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1605).jpg: 640x576 (no detections), 13.7ms\n",
      "Speed: 0.2ms preprocess, 13.7ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1704).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1145).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1746).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2256).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (674).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1790).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (3).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2188).jpg: 288x640 1 face, 8.4ms\n",
      "Speed: 0.1ms preprocess, 8.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2350).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1804).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (597).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1635).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1823).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (912).jpg: 480x640 (no detections), 9.5ms\n",
      "Speed: 0.1ms preprocess, 9.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2012).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (35).jpg: 640x512 (no detections), 8.8ms\n",
      "Speed: 0.2ms preprocess, 8.8ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1409).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1727).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (820).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1370).jpg: 640x640 1 face, 12.8ms\n",
      "Speed: 0.2ms preprocess, 12.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (964).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2059).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (764).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (842).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1057).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1278).jpg: 640x480 1 face, 9.5ms\n",
      "Speed: 0.3ms preprocess, 9.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1950).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2649).jpg: 640x480 (no detections), 9.4ms\n",
      "Speed: 0.3ms preprocess, 9.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1726).jpg: 640x448 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1163).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (344).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (451).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (622).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (164).jpg: 640x576 1 face, 13.6ms\n",
      "Speed: 0.2ms preprocess, 13.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2058).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.3ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2106).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2040).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2444).jpg: 544x640 1 face, 13.3ms\n",
      "Speed: 0.5ms preprocess, 13.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (246).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (261).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1249).jpg: 640x512 1 face, 8.7ms\n",
      "Speed: 0.2ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2149).jpg: 640x416 1 face, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (631).jpg: 640x448 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1253).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1418).jpg: 640x608 1 face, 13.8ms\n",
      "Speed: 0.2ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (747).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (628).jpg: 640x480 2 faces, 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1864).jpg: 640x480 (no detections), 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2349).jpg: 640x544 1 face, 12.6ms\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1912).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1751).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (455).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (111).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2008).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (666).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1233).jpg: 640x448 (no detections), 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1938).jpg: 640x384 1 face, 8.4ms\n",
      "Speed: 0.2ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (151).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (752).jpg: 480x640 1 face, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2445).jpg: 640x512 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1387).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (577).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (118).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (660).jpg: 640x416 1 face, 9.1ms\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (417).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1997).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2629).jpg: 480x640 (no detections), 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (382).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2638).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1259).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1151).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (166).jpg: 640x512 1 face, 9.0ms\n",
      "Speed: 0.1ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1031).jpg: 640x544 1 face, 12.7ms\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (700).jpg: 640x480 1 face, 9.4ms\n",
      "Speed: 0.2ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1450).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.2ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (652).jpg: 640x480 2 faces, 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1745).jpg: 640x448 2 faces, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2298).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (868).jpg: 640x512 1 face, 8.9ms\n",
      "Speed: 0.1ms preprocess, 8.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1514).jpg: 640x448 1 face, 9.2ms\n",
      "Speed: 0.1ms preprocess, 9.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (84).jpg: 640x352 1 face, 8.3ms\n",
      "Speed: 0.1ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (732).jpg: 640x480 1 face, 9.3ms\n",
      "Speed: 0.2ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (1136).jpg: 640x480 1 face, 9.1ms\n",
      "Speed: 0.2ms preprocess, 9.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (466).jpg: 640x448 (no detections), 9.2ms\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (713).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (2179).jpg: 640x448 (no detections), 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (71).jpg: 640x448 1 face, 9.0ms\n",
      "Speed: 0.2ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/joowan/Desktop/face_pr/data/gender/1/1 (678).jpg: 640x480 (no detections), 9.3ms\n",
      "Speed: 0.1ms preprocess, 9.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "for i,img in enumerate(woman_jpg_imgs):\n",
    "    result=model(source=img)\n",
    "    orig_img=result[0].orig_img\n",
    "    opencv_img=cv2.cvtColor(orig_img,cv2.COLOR_BGR2RGB)\n",
    "    boxes=result[0].boxes.xyxy.cpu().numpy()\n",
    "    for box in boxes:\n",
    "        x1=int(box[0])\n",
    "        y1=int(box[1])\n",
    "        x2=int(box[2])\n",
    "        y2=int(box[3])\n",
    "        cv2.rectangle(opencv_img,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "        crop=opencv_img[y1:y2,x1:x2]\n",
    "        crop=cv2.cvtColor(crop,cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite(f'data/gender/woman/{i}.jpg',crop)\n",
    "\n",
    "for i,img in enumerate(man_jpg_imgs):\n",
    "    result=model(source=img)\n",
    "    orig_img=result[0].orig_img\n",
    "    opencv_img=cv2.cvtColor(orig_img,cv2.COLOR_BGR2RGB)\n",
    "    boxes=result[0].boxes.xyxy.cpu().numpy()\n",
    "    for box in boxes:\n",
    "        x1=int(box[0])\n",
    "        y1=int(box[1])\n",
    "        x2=int(box[2])\n",
    "        y2=int(box[3])\n",
    "        cv2.rectangle(opencv_img,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "        crop=opencv_img[y1:y2,x1:x2]\n",
    "        crop=cv2.cvtColor(crop,cv2.COLOR_BGR2RGB)\n",
    "        cv2.imwrite(f'data/gender/man/{i}.jpg',crop)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
